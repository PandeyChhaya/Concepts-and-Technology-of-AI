{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1bA7mWuzgNr-UWvuKwMDEV_5bbnAE_59x",
      "authorship_tag": "ABX9TyNWeTZz0CZY8YMZIUiIZPbC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PandeyChhaya/Concepts-and-Technology-of-AI/blob/main/Worksheet5_ChhayaPandey240001.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/Concepts and Technology of AI/student.csv\")\n",
        "\n",
        "# Check the first and last five rows\n",
        "print(\"First 5 rows:\\n\", data.head())\n",
        "print(\"\\nLast 5 rows:\\n\", data.tail())\n",
        "\n",
        "# Dataset information\n",
        "print(\"\\nDataset Info:\")\n",
        "data.info()\n",
        "\n",
        "# Descriptive statistics\n",
        "print(\"\\nDescriptive Statistics:\")\n",
        "print(data.describe())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88RTtkZqzImn",
        "outputId": "e2e016e2-7fdc-42ae-9e7d-0a1733925374"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 rows:\n",
            "    Math  Reading  Writing\n",
            "0    48       68       63\n",
            "1    62       81       72\n",
            "2    79       80       78\n",
            "3    76       83       79\n",
            "4    59       64       62\n",
            "\n",
            "Last 5 rows:\n",
            "      Math  Reading  Writing\n",
            "995    72       74       70\n",
            "996    73       86       90\n",
            "997    89       87       94\n",
            "998    83       82       78\n",
            "999    66       66       72\n",
            "\n",
            "Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000 entries, 0 to 999\n",
            "Data columns (total 3 columns):\n",
            " #   Column   Non-Null Count  Dtype\n",
            "---  ------   --------------  -----\n",
            " 0   Math     1000 non-null   int64\n",
            " 1   Reading  1000 non-null   int64\n",
            " 2   Writing  1000 non-null   int64\n",
            "dtypes: int64(3)\n",
            "memory usage: 23.6 KB\n",
            "\n",
            "Descriptive Statistics:\n",
            "              Math      Reading      Writing\n",
            "count  1000.000000  1000.000000  1000.000000\n",
            "mean     67.290000    69.872000    68.616000\n",
            "std      15.085008    14.657027    15.241287\n",
            "min      13.000000    19.000000    14.000000\n",
            "25%      58.000000    60.750000    58.000000\n",
            "50%      68.000000    70.000000    69.500000\n",
            "75%      78.000000    81.000000    79.000000\n",
            "max     100.000000   100.000000   100.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = data[['Math', 'Reading']].values\n",
        "Y = data['Writing'].values\n"
      ],
      "metadata": {
        "id": "aWoWGUNu0ZVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Manual Train-Test Split Split the dataset into training and testing sets (80%-20%) manually."
      ],
      "metadata": {
        "id": "nw_pWfHP0fh0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def manual_train_test_split(X, Y, test_size=0.2, random_state=None):\n",
        "    if random_state is not None:\n",
        "        np.random.seed(random_state)\n",
        "\n",
        "    indices = np.arange(len(X))\n",
        "    np.random.shuffle(indices)\n",
        "\n",
        "    split_idx = int(len(X) * (1 - test_size))\n",
        "    train_indices = indices[:split_idx]\n",
        "    test_indices = indices[split_idx:]\n",
        "\n",
        "    X_train = X[train_indices]\n",
        "    X_test = X[test_indices]\n",
        "    Y_train = Y[train_indices]\n",
        "    Y_test = Y[test_indices]\n",
        "\n",
        "    return X_train, X_test, Y_train, Y_test\n",
        "\n",
        "# Perform train-test split\n",
        "X_train, X_test, Y_train, Y_test = manual_train_test_split(X, Y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "DEQm0JN80jt1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5) Define the Cost Function Manually implement the Mean Squared Error (MSE) as the cost function."
      ],
      "metadata": {
        "id": "tsPEr35i0qQS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cost_function(X, Y, W):\n",
        "    predictions = np.dot(X, W)\n",
        "    errors = predictions - Y\n",
        "    cost = np.mean(errors ** 2) / 2\n",
        "    return cost\n"
      ],
      "metadata": {
        "id": "ZCDIvvl_0t1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Implement Gradient Descent Optimize the weights using gradient descent."
      ],
      "metadata": {
        "id": "YWlSTc9F0wau"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent(X, Y, W, alpha, iterations):\n",
        "    m = len(Y)\n",
        "    cost_history = []\n",
        "\n",
        "    for _ in range(iterations):\n",
        "        predictions = np.dot(X, W)\n",
        "        errors = predictions - Y\n",
        "        gradient = np.dot(X.T, errors) / m\n",
        "        W -= alpha * gradient\n",
        "        cost = cost_function(X, Y, W)\n",
        "        cost_history.append(cost)\n",
        "\n",
        "    return W, cost_history"
      ],
      "metadata": {
        "id": "slnTJCt800US"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Model Evaluation Implement RMSE and RÂ² evaluation metrics from scratch."
      ],
      "metadata": {
        "id": "97RDiNhi04GI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rmse(Y, Y_pred):\n",
        "    return np.sqrt(np.mean((Y_pred - Y) ** 2))\n",
        "\n",
        "def r2(Y, Y_pred):\n",
        "    ss_res = np.sum((Y - Y_pred) ** 2)\n",
        "    ss_tot = np.sum((Y - np.mean(Y)) ** 2)\n",
        "    return 1 - (ss_res / ss_tot)"
      ],
      "metadata": {
        "id": "uJfJPrUf0_SD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8.Integrate All Steps Combine everything into a main function to execute the workflow."
      ],
      "metadata": {
        "id": "Z1krwseD1EXR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "\n",
        "    data = pd.read_csv('/content/drive/MyDrive/Concepts and Technology of AI/student.csv')\n",
        "    X = data[['Math', 'Reading']].values\n",
        "    Y = data['Writing'].values\n",
        "\n",
        "    # Step 2: Split the dataset\n",
        "    X_train, X_test, Y_train, Y_test = manual_train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Step 3: Initialize weights and parameters\n",
        "    W = np.zeros(X_train.shape[1])  # Initialize weights\n",
        "    alpha = 0.01  # Learning rate\n",
        "    iterations = 1000  # Number of iterations\n",
        "\n",
        "    # Step 4: Perform gradient descent\n",
        "    W_optimal, cost_history = gradient_descent(X_train, Y_train, W, alpha, iterations)\n",
        "\n",
        "    # Step 5: Make predictions\n",
        "    Y_pred = np.dot(X_test, W_optimal)\n",
        "\n",
        "    # Step 6: Evaluate the model\n",
        "    model_rmse = rmse(Y_test, Y_pred)\n",
        "    model_r2 = r2(Y_test, Y_pred)\n",
        "\n",
        "    # Step 7: Output results\n",
        "    print(\"Final Weights:\", W_optimal)\n",
        "    print(\"Cost History (First 10 iterations):\", cost_history[:10])\n",
        "    print(\"RMSE on Test Set:\", model_rmse)\n",
        "    print(\"R-Squared on Test Set:\", model_r2)\n",
        "\n",
        "# Run the main function\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0a8NSaV1KcD",
        "outputId": "dd05e978-a02e-469c-82c0-24ad299f1eaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Weights: [nan nan]\n",
            "Cost History (First 10 iterations): [23036510.873437613, 216969014973.9958, 2043520376885335.8, 1.924687509625204e+19, 1.8127648990481012e+23, 1.7073507064327466e+27, 1.6080664604037283e+31, 1.5145556980956626e+35, 1.426482685335115e+39, 1.34353121124526e+43]\n",
            "RMSE on Test Set: nan\n",
            "R-Squared on Test Set: nan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:118: RuntimeWarning: overflow encountered in reduce\n",
            "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
            "<ipython-input-5-4f81e4d6e87a>:4: RuntimeWarning: overflow encountered in square\n",
            "  cost = np.mean(errors ** 2) / 2\n",
            "<ipython-input-6-c15d76096df0>:9: RuntimeWarning: invalid value encountered in subtract\n",
            "  W -= alpha * gradient\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "    9. Experiment with Learning Rates Test the model with different learning rates (alpha):\n",
        "\n",
        "Low learning rate (e.g., alpha = 0.001) to observe slow convergence. High learning rate (e.g., alpha = 0.1) to test for divergence or fast convergence. Modify the alpha value in the main() function to experiment.\n"
      ],
      "metadata": {
        "id": "AKHQHIBe1ckF"
      }
    }
  ]
}